\input{../header}

\newcommand\CHAPTER{8}
\title{Lesson {\CHAPTER}:\\Case study: Panel data on dynamic variation\\ in sexual contact rates}
\author{Edward L. Ionides, Aaron A. King, and Kidus Asfaw}

\begin{document}

<<setup, child="../setup.Rnw",include=FALSE,cache=FALSE,purl=FALSE>>=
@

<<parallel,echo=FALSE,cache=FALSE,purl=TRUE>>=
DEBUG <- FALSE
# DEBUG <- TRUE
library(doParallel)
library(doRNG)
cores <- detectCores()
registerDoParallel(cores)
registerDoRNG(2050320976)
@

\maketitle

\mode<article>{\tableofcontents}

\mode<presentation>{
  \begin{frame}{Outline}
    \tableofcontents
  \end{frame}
}

\begin{frame}{Objectives}

  \begin{enumerate}

  \item Discuss the use of partially observed Markov process (POMP) methods for panel data, also known as longitudinal data.

  \item See how POMP methods can be used to understand the outcomes of a longitudinal behavioral survey on sexual contact rates.

  \item Introduce the \Rlanguage package \package{panelPomp} that extends \package{pomp} to panel data.

  \end{enumerate}
\end{frame}


\section{Panel data}

\begin{frame}{Introduction to panel data}

  \bi

\item Panel data consist of a collection of time series having no dynamic coupling.

\item Each time series is called a \myemph{unit}

\item If each unit contain insufficient information to estimate model parameters, we infer \myemph{shared parameters} by pooling across the whole panel.

\item We may have \myemph{unit-specific parameters}, taking distinct values for each unit.

\item The goals of developing, fitting and criticizing mechanistic models for panel data are similar to analysis of a single time series.

  \ei

\end{frame}

\section{Heterogeneity in sexual contact rates}

\begin{frame}[fragile]

  \frametitle{Heterogeneities in sexual contacts}

  \bi

\item Basic epidemiological models suppose equal contact rates for all individuals in a population. 

\item Sometimes these models are extended to permit rate heterogeneity between individuals. 

\item Rate heterogeneity within individuals, i.e., dynamic behavioral change, has rarely been considered. 

\item There have been some indications that rate heterogeneity plays a substantial role in the HIV epidemic. 

  \ei

\end{frame}

\begin{frame}[fragile]  

  \frametitle{Data from a prospective study}

  \bi

\item \citet{romero-severson15} investigated whether dynamic variation in sexual contact rates are a real and measurable phenomenon.
\item They analyzed a large cohort study of HIV-negative gay men in 3 cities \citep{vittinghoff99}. 

\item In a simple model for HIV, with a fully mixing population of susceptible and infected individuals, the fitted variation found by \citet{romero-severson15} can explain the observed prevalence history in the US despite the low per-contact infectivity of HIV.

\item Here, we consider the longitudinal data from \citet{vittinghoff99} on total sexual contacts over four consecutive 6-month periods, for the 882 men having no missing observations. 

  \ei

\end{frame}

\begin{frame}[fragile]

  \bi

\item Plotted is a sample of 15 time series from \link{https://kingaa.github.io/sbied/contacts/contacts.csv}{contacts.csv}.

  \ei

  <<data_code,echo=T,eval=F,purl=F>>=
  contact_data <- read.table(file="contacts.csv",header=TRUE)
  matplot(t(contact_data[1:15,1:4]),
          ylab="total sexual contacts",xlab="6-month intervals", 
          type="l",xaxp=c(1,4,3))
  @
  
  \hspace{-10mm}

  <<data_plot,echo=F,eval=T,fig.width=5,fig.height=3,out.width="10cm">>=
  par(mai=c(0.8,0.8,0.1,0.1))
  <<data_code>>
  @
  
\end{frame}

\frametitle{Modeling sexual contact rate heterogeneity}

\begin{frame}[fragile]  

  \frametitle{Types of contact rate heterogeneity}

  We want a model that can describe all sources of variability in the data:

  \begin{enumerate}

  \item Differences between individuals

  \item Differences within individuals over time

  \item Over-dispersion: variances exceeding that of a Poisson model

  \end{enumerate}

\end{frame}

\begin{frame}[fragile]  

  \frametitle{A model for dynamic variation in sexual contact rates}

  \bi

\item We use the model of \citet{romero-severson15}, with each individual making contacts at a latent rate $X_i(t)$.

\item Each data point, $y_{ij}$, is the number of reported contacts for individual $i$ between time $t_{j-1}$ and $t_j$, where $i=1,\dots,882$ and $j=1,\dots,4$.

\item The unobserved process $\{X_i(t)\}$ is connected to the data through the expected number of contacts for individual $i$ in reporting interval $j$, which we write as
  $$C_{ij}= \alpha^{j-1}\int_{t_{j-1}}^{t_j} X_i(t)\, dt,$$
  where $\alpha$ is an additional secular trend that accounts for the observed decline in reported contacts.


  \ei

\end{frame}

\begin{frame}[fragile]

  \frametitle{Overdispersion relative to Poisson variation}

  \bi

\item A basic stochastic model for homogeneous count data models $y_{ij}$ as a Poisson random variable with mean and variance equal to $C_{ij}$
  \citep{Keeling2009}.

\item However, the variance in the data are much higher than the mean of the data \citep{romero-severson12-scid}.

\item Therefore, we model the data as negative binomial, a generalization of a Poisson distribution that permits variance larger than the mean:
  $$y_{ij}\sim \mathrm{NegBin}\, \left(C_{ij},D_{i}\right),$$
  with mean $C_{ij}$ and  variance $C_{ij}+C_{ij}^2/D_i$.

\item Here, $D_i$ is called the dispersion parameter, with the Poisson model being recovered in the limit as $D_i$ becomes large.

\item The dispersion, $D_i$, can model increased variance (compared to Poisson variation) for individual contacts, but cannot explain observed autocorrelation between measurements on an individual over time.

  \ei

\end{frame}

\begin{frame}[fragile]

  \frametitle{Autocorrelation and individual-level effects}

  \bi

\item To model autocorrelation, we suppose that individual $i$ has behavioral episodes within which $X_i(t)$ is constant, but the individual enters new behavioral episodes at rate $R_i$. 
  At the start of each episode, $X_i(t)$ takes a new value drawn from a Gamma distribution with mean $\mu_X$ and variance $\sigma_X$,
  $$X_i(t)\sim \mbox{Gamma}(\mu_X, \sigma_X).$$

\item To complete the model, we also assume Gamma distributions for $D_i$ and $R_i$,
  $$D_i \sim \mbox{Gamma}(\mu_D, \sigma_D),$$
  $$R_i \sim \mbox{Gamma}(\mu_R, \sigma_R).$$
  The parameters, $\sigma_X$, $\sigma_D$ and $\sigma_R$ control individual-level differences in behavioral parameters allowing the model to encompass a wide range of sexual contact patterns.

  \ei

\end{frame}

\begin{frame}[fragile]

  \frametitle{Parameter interpretation and identifiability}

  \bi

\item The distinction between the effects of the rate at which new behavioral episodes begin, $R_i$, and the dispersion parameter, $D_i$, is subtle since both model within-individual variability.

\item The signal in the data about distinct behavioral episodes could be overwhelmed by a high variance in number of reported contacts resulting from a low value of $D_i$.

\item Whether the data are sufficient to identify both $R_i$ and $D_i$ is an empirical question.

  \ei

\end{frame}

\section{Simulation-based investigation of the fitted model}

\begin{frame}[fragile] 

  \frametitle{Consequences of dynamic behavior in an SI model for HIV}

  \bi
\item 3 cases where contact rates are either (a) constant; (b) vary only between individuals; (c) vary both between and within individuals. 

\item In each case, parameterize the model by fitting the behavioral model above, and supplying per-contact infection rates from the literature. 

\item This simple model shows a potential role for dynamic variation.

  \ei

  \parbox{6cm}{
    <<plot_dynamics,out.width="6cm",echo=F,purl=FALSE>>=
    knitr::include_graphics("contacts_fig4.jpg")
    @
  }
  \hspace{-3mm}
  \parbox{2mm}{
    (c)

    \vspace{15mm}

    (b)

    \vspace{8mm}

    (a)
  }
  \hspace{8mm}
  \parbox{4.5cm}{
    Fig 4 of  \citet{romero-severson15}. The median of 500 simulations are shown as lines and the $75^{th}$ and $25^{th}$ percentiles are shown as gray envelopes.

  }
\end{frame}

\begin{frame}[fragile]

  \bi

\item 'Homogeneous' (dashed line): the epidemic was simulated where $\mu_X$ is estimated by the sample mean (1.53 $\mathrm{month}^{-1}$) without any sources of between-individual or within-individual heterogeneity.

\item 'Between Heterogeneity' (dotted line): the epidemic was simulated where $\mu_X$ is estimated by the sample mean (1.53 $\mathrm{month}^{-1}$) and $\sigma_X$ is estimated by the sample standard deviation (3.28 $\mathrm{month}^{-1}$)

\item 'Within+Between Heterogeneity' (solid line): the epidemic was simulated where each parameter is set to the estimated maximum likelihood estimate for total contacts.

\item For all situations, the per contact probability of transmission was set to 1/120, the average length of infection was set to 10 years, and the infection-free equilibrium population size was set to 3000. The per contact probability was selected such that the basic reproduction number in the the 'Homogeneous' case was 1.53. In the 'Homogeneous', 'Between Heterogeneity', `Within+Between Heterogeneity' cases respectively 239/500 and 172/500, 95/500 simulations died out before the 100 year mark.

  \ei

\end{frame}

\section{PanelPOMP models and the \package{panelPomp} package}

\begin{frame}[fragile] 

  \frametitle{PanelPOMP models as an extension of POMP models}

  \bi

\item A PanelPOMP model consists of independent POMP models for a collection of \myemph{units}.

\item The POMP models are tied together by shared parameters. 

\item Here, the units are individuals in the longitudinal survey.

\item In general, some parameters may be \myemph{unit-specific} (different for each individual) whereas others are \myemph{shared} (common to all individuals).

\item Here, we only have shared parameters. The heterogeneities between individuals are modeled as \myemph{random effects} with distribution determined by these shared parameters.

\item Iterated filtering for POMP models was extended to PanelPOMPs by \citet{breto19}. 

  \ei

\end{frame}

\begin{frame}[fragile] 

  \frametitle{Using the \package{panelPomp} R package}

  \bi

\item The main task of \package{panelPomp} beyond \package{pomp} is to handle the additional book-keeping necessitated by the unit structure.

\item PanelPOMP models also motivate methodological developments to deal with large datasets and the high dimensional parameter vectors that can result from unit-specific parameters.

\item A \code{panelPomp} object for the above contact data and model is provided by \code{pancon} in \package{panelPomp}.

  \ei

  <<load-pancon,cache=F>>=
  library(panelPomp)
  contacts <- panelPompExample(pancon)
  @
  
  \bi

\item The implementation of the above model equations in \code{contacts} can be found in the \link{https://github.com/cbreto/panelPomp/blob/master/inst/examples/pancon.R}{\code{panelPomp source code on github}}.


  \ei

\end{frame}

\begin{frame}[fragile]

  \vspace{-3mm}

  \bi

\item Let's start by exploring the \code{contacts} object

  \ei

  \vspace{-1mm}

  <<class_contacts>>=
  class(contacts)
  slotNames(contacts)
  class(unitobjects(contacts)[[1]])
  @
  
  \vspace{-2mm}

  \bi

\item We see that an object of class \code{panelPomp} is a list of \code{pomp} objects together with a parameter specification permitting shared and/or unit-specific parameters.

\item The POMP models comprising the PanelPOMP model do not need to have the same observation times for each unit.

  \ei

\end{frame}

\begin{frame}[fragile]{\myexercise. A PanelPOMP with all parameters unit-specific}

Suppose a PanelPOMP model has all its parameters unit-specific. Is there anything useful to be gained from the PanelPOMP structure, or is it preferable to analyze the data as a collection of POMP models?

  \vspace{3mm}

  \link{https://kingaa.github.io/sbied/contacts/Q-unit-specific.html}{Worked solution}


\end{frame}

\begin{frame}[fragile]{\myexercise. Methods for panelPomps}

How would you find the \package{panelPomp} package methods available for working with a \code{panelPomp} object?  


  \vspace{3mm}

  \link{https://kingaa.github.io/sbied/contacts/Q-panelPomp-methods.html}{Worked solution}


\end{frame}

\section{Likelihood-based inference for PanelPOMPs}

\begin{frame}[fragile] 

  \frametitle{Likelihood evaluation for PanelPOMPs}

  \bi

\item PanelPOMP models are closely related to POMPs, and particle filter methods remain applicable.

\item \code{contacts} contains a parameter vector corresponding to the MLE for total contacts reported by \citet{romero-severson15}:

  \ei

  <<coef>>=
  coef(contacts)
  @
  
  \bi

\item \code{pfilter(contacts,Np=1000)} carries out a particle filter computation at this parameter vector.

  \ei

\end{frame}

\begin{frame}[fragile]{\myexercise. What happens when we \code{pfilter} a \code{panelPomp}}

  \bi

\item Describe what you think \code{pfilter(contacts,Np=1000)} should do. 

\item Hypothesize what might be the class of the resulting object? What slots might this object possess?

\item Check your hypothesis.

  \ei

  \link{https://kingaa.github.io/sbied/contacts/Q-pfilter-for-panelPomp.html}{Worked solution}


\end{frame}

\begin{frame}[fragile]  

  \frametitle{Replicated likelihood evaluations}

  \bi

\item 
  As usuual for Monte Carlo calculations, it is useful to replicate the likelihood evaluations, both to reduce Monte Carlo uncertainty and (perhaps more importantly) to quantify it. 

  \ei

  <<pfilter1-code,eval=F,echo=T,purl=F>>=
  pf1_results <- foreach(i=1:20) %dopar% {
    library(panelPomp)
    pf <- pfilter(contacts,Np= if(DEBUG) 10 else 2000)
    list(logLik=logLik(pf),
         unitLogLik=sapply(unitobjects(pf),logLik))
  }
  @
  
  <<pfilter1-eval,cache=F,echo=F>>=
  stew("results/pfilter1.rda",{
    tic <- Sys.time()
    eval_cores <- cores
    <<pfilter1-code>>
    t1 <- as.numeric(difftime(Sys.time(),tic,units="mins"))
  }) 
  @
  
  \bi

\item This took \Sexpr{round(t1,1)} minutes using \Sexpr{eval_cores} cores.

  \ei

\end{frame}

\subsection{Combining likelihood evaluations}

\begin{frame}[fragile]  

  \frametitle{Combining Monte Carlo likelihood evaluations for PanelPOMPs \rule[-2mm]{0mm}{3mm}}

  \bi

\item We have a new consideration not found with \code{pomp} models. 
  Each unit has its own log likelihood arising from an independent Monte Carlo computation.

\item The basic \code{pomp} approach remains valid:

  \ei

  <<loglik1>>=
  loglik1 <- sapply(pf1_results,function(x) x$logLik)
  logmeanexp(loglik1,se=T)
  @
  
  \bi

\item Can we do better, using the independence of units? It turns out we can \citep{breto19}.

  \ei

\end{frame}

\begin{frame}[fragile]

  \frametitle{\code{logmeanexp} versus \code{panel\_logmeanexp}}

  <<panel_logmeanexp>>=
  pf1_loglik_matrix <- sapply(pf1_results,function(x) x$unitLogLik)
  panel_logmeanexp(pf1_loglik_matrix,MARGIN=1,se=T)
  @
  
  \bi

\item The improvement via \code{panel\_logmeanexp} is small in this case, since the number of observation times is small.

\item For longer panels, the difference becomes more important.
  \ei

\end{frame}

\begin{frame}[fragile]{\myexercise.  The difference between \code{panel\_logmeanexp} and \code{logmeanexp}}

  \bi

\item The basic \code{pomp} approach averages the Monte Carlo likelihood estimates after aggregating the likelihood over units.

\item The \code{panel\_logmeanexp} averages separately for each unit before combining.

\item Why does the latter typically give a higher log likelihood estimate with lower Monte Carlo uncertainty?

\item Either reason at a heuristic level or (optionally) develop a mathematical argument.

  \ei

  \vspace{3mm}

  \link{https://kingaa.github.io/sbied/contacts/Q-panel-logmeanexp.html}{Worked solution}


\end{frame}


\begin{frame}[fragile]

  \frametitle{Writing a PanelPOMP as a POMP}

  \bi

\item If we can formally write a PanelPOMP as a POMP, we can use methods such as \code{mif2} for inference.

\item We could stack the panel models in different ways to make a large POMP model.

\item A naive way to do inference for a PanelPOMP model as a POMP is to let an observation for the POMP be a vector of observations for all units in the PanelPOMP at that time. This gives a high-dimensional observation vector which is numerically intractable via particle filters.

\item Instead, we concatenate the panels into one long time series, with dynamic breaks where the panels are glued together.

  \ei

\end{frame}

\subsection{Maximizing the likelihood}

\begin{frame}[fragile]  

  \frametitle{Likelihood maximization using the PIF algorithm}

  \bi

\item The panel iterated filtering (PIF) algorithm of \citet{breto19} applies the IF2 algorithm to a POMP model constructed by concanenating the collection of panels.

\item PIF is implemented in \package{panelPomp} as the \code{mif2} method for class \code{panelPomp}. 

\item Comparing \code{?panelPomp::mif2} with \code{?pomp::mif2} reveals that the only difference in the arguments is that the \code{params} argument for \code{pomp::mif2} becomes \code{shared.start} and \code{specific.start} for \code{panelPomp::mif2}.

\item As an example of an iterated filtering investigation, let's carry out a local search, starting at the current estimate of the MLE.

\item Following \citet{romero-severson15} we fix $\sigma_R=0$.
  \ei

\end{frame}

\begin{frame}[fragile]

  <<mif1-code,eval=F,echo=T,purl=F>>=
  mif_results <- foreach(i=1:20) %dopar% {
    library(pomp); library(panelPomp)
    mf <- mif2(contacts,
      Nmif = if(DEBUG) 2 else 50,
      Np = if(DEBUG) 5 else 1000,
      cooling.type="geometric", # needed for panelPomp 0.10
      cooling.fraction.50=0.5,
      rw.sd=rw.sd(mu_X=0.02, sigma_X=0.02,mu_D = 0.02,
        sigma_D=0.02,mu_R=0.02, alpha=0.02)
    )
    list(logLik=logLik(mf),params=coef(mf))
  }
@

<<mif1-stew,cache=F,eval=T,echo=F>>=
stew("results/mif1.rda",{
  mif_cores <- cores
  tic <- Sys.time()
<<mif1-code>>
  t2 <- difftime(Sys.time(),tic,units="mins")
})
@

\bi

\item This search took \Sexpr{round(as.numeric(t2),1)} minutes on \Sexpr{mif_cores} cores.

\item We see that \code{panelPomp} iterated filtering is set up similarly to its \code{pomp} cousin. 

\ei

\end{frame}

\begin{frame}[fragile]
\frametitle{Some considerations for likelihood evaluations}

Similar likelihood evaluation issues arise for \package{panelPomp} as for {pomp}.
\bi

\item The preliminary likelihood estimated as a consequence of running \code{mif2} and extracted here by \code{sapply(m2,logLik)} does not correspond to the actual, fixed parameter, model. It is the sequential Monte Carlo estimate of the likelihood from the last filtering iteration, and therefore will have some perturbation of the parameters.

\item One typically requires fewer particles for each filtering iteration than necessary to obtain a good likelihood estimate---stochastic errors can cancel out through the filtering iterations, rather than within any one iteration. 

\item For promising new parameter values, it is desirable to put computational effort into evaluating the likelihood sufficient to make the Monte Carlo error small compared to one log unit.

\ei


\end{frame}

\begin{frame}[fragile]

<<mif1-lik-eval-code,eval=F,echo=T,purl=F>>=
mif_logLik <-  sapply(mif_results,function(x)x$logLik)
mif_mle <- mif_results[[which.max(mif_logLik)]]$params
pf3_loglik_matrix <- foreach(i=1:10,.combine=rbind) %dopar% {
  library(panelPomp)
  unitlogLik(pfilter(contacts,
    shared=mif_mle,Np=if(DEBUG) 50 else 10000))
}  
@

<<mif1-lik-eval,cache=F,echo=F>>=
stew("results/mif1-lik-eval.rda",{
tic <- Sys.time()
<<mif1-lik-eval-code>>
t3 <- difftime(Sys.time(),tic,units="mins")
mif_lik_eval_cores <- cores
})
@

<<panel-logmeanexp>>=
panel_logmeanexp(pf3_loglik_matrix,MARGIN=2,se=T)
@

\bi
\item This took \Sexpr{round(as.numeric(t3),1)} minutes on \Sexpr{mif_lik_eval_cores} cores.

\item Here, the local search found a lower likelhood that the published MLE. Longer searches with more cooling, and/or more Monte Carlo replications, may be needed to reliably obtain accurate maximization.

\ei

\end{frame}  

\mode<presentation>{
  \begin{frame}[allowframebreaks=0.8]{References}
    \bibliography{../sbied}
  \end{frame}
}
\mode<article>{
  \bibliography{../sbied}
}

\begin{frame}{License, acknowledgments, and links}

  \begin{itemize}
  \item
    This lesson is prepared for the \link{https://kingaa.github.io/sbied/}{Simulation-based Inference for Epidemiological Dynamics} module at the 2020 Summer Institute in Statistics and Modeling in Infectious Diseases, \link{https://www.biostat.washington.edu/suminst/sismid}{SISMID 2020}.

  \item
    The materials build on \link{../acknowledge.html}{previous versions of this course and related courses}.

  \item
    Licensed under the \link{http://creativecommons.org/licenses/by-nc/4.0/}{Creative Commons Attribution-NonCommercial license}.
    Please share and remix non-commercially, mentioning its origin.
    \includegraphics[height=12pt]{../graphics/cc-by-nc}

  \item
    Produced with R version \Sexpr{getRversion()} and \package{pomp} version \Sexpr{packageVersion("pomp")}.

  \item
    Compiled on \today.

  \end{itemize}

  \link{../index.html}{Back to course homepage}
  
  \link{https://raw.githubusercontent.com/kingaa/sbied/master/contacts/main.R}{\Rlanguage codes for this lesson}
\end{frame}

\end{document}

