\usepackage[round,authoryear]{natbib}
\usepackage{paralist}
\usepackage{pgfpages}

\usefonttheme[onlymath]{serif}

\newcommand\prob[1]{\mathbb{P}\left[{#1}\right]}
\newcommand\expect[1]{\mathbb{E}\left[{#1}\right]}
\newcommand\var[1]{\mathrm{Var}\left[{#1}\right]}
\newcommand\dist[2]{\mathrm{#1}\left(#2\right)}
\newcommand\dlta[1]{{\Delta}{#1}}
\newcommand\lik{\mathcal{L}}
\newcommand\loglik{\ell}
\newcommand\Rzero{\mathfrak{R}_0}

\newcommand\code[1]{\texttt{#1}}
\newcommand\package[1]{\textbf{#1}}

\newcommand\link[2]{\href{#1}{\textcolor{blue}{#2}}}

\usepackage{xspace}        
\newcommand\Rlanguage{\textsf{R}\xspace}

\usepackage{amssymb}
\usepackage{graphicx}

\mode<beamer>{\usetheme{AnnArbor}}
\mode<beamer>{\setbeamertemplate{footline}}
\mode<beamer>{\setbeamertemplate{footline}[frame number]}
\mode<beamer>{\setbeamertemplate{frametitle continuation}[from second][\insertcontinuationcountroman]}
\mode<beamer>{\setbeamertemplate{navigation symbols}{}}

\mode<handout>{\pgfpagesuselayout{2 on 1}[letterpaper,border shrink=5mm]}

\def\CHAPTER{4}
\title{Lesson \CHAPTER.\\Iterated filtering: principles and practice}
\author{Edward Ionides, Aaron A. King, and Kidus Asfaw}

\begin{document}

% knitr set up
<<knitr_opts,echo=F,cache=F,purl=F>>=
library(knitr)
prefix <- "mif"
opts_chunk$set(
             progress=TRUE,
             prompt=FALSE,
             tidy=FALSE,
             highlight=TRUE,
             strip.white=TRUE,
             warning=FALSE,
             message=FALSE,
             error=FALSE,
             echo=TRUE,
             cache=TRUE,
             cache.extra=rand_seed,
             results='markup',
             fig.show='asis',
             size='small',
             fig.path=paste0("figure/",prefix,"-"),
             cache.path=paste0("cache/",prefix,"-"),
             fig.align='center',
             fig.height=4,fig.width=6.83,
             dpi=100,
             dev='png',
             dev.args=list(bg='transparent'),
             comment=NA
           )
options(
  keep.source=TRUE,
  encoding="UTF-8",
  width = 60
)

myround<- function (x, digits = 1) {
                                        # taken from the broman package
  if (digits < 1) 
    stop("This is intended for the case digits >= 1.")
  if (length(digits) > 1) {
    digits <- digits[1]
    warning("Using only digits[1]")
  }
  tmp <- sprintf(paste("%.", digits, "f", sep = ""), x)
  zero <- paste0("0.", paste(rep("0", digits), collapse = ""))
  tmp[tmp == paste0("-", zero)] <- zero
  tmp
}
@


<<prelims,echo=F,cache=F>>=
library(tidyverse)
library(pomp)
stopifnot(getRversion() >= "4.0")
stopifnot(packageVersion("pomp")>="3.0")
theme_set(theme_bw())
set.seed(1350254336)
@

\maketitle

\mode<article>{\tableofcontents}

\mode<presentation>{
  \begin{frame}{Outline}
    \tableofcontents
  \end{frame}
}

\section{Introduction}

\begin{frame}{Introduction}
  \begin{itemize}
  \item This tutorial covers likelihood estimation via the method of iterated filtering.
  \item It presupposes familiarity with building partially observed Markov process (POMP) objects in the \Rlanguage package \package{pomp} \citep{King2016}. 
  \item This tutorial follows on from the \link{../pfilter/pfilter.html}{topic of particle filtering} (also known as sequential Monte Carlo) via \code{pfilter} in \package{pomp}. 
  \end{itemize}
\end{frame}

\begin{frame}{Objectives}
  \begin{enumerate}
  \item<+-> To review the available options for inference on POMP models, to put iterated filtering in context.
  \item<+-> To understand how iterated filtering algorithms carry out repeated particle filtering operations, with randomly perturbed parameter values, in order to maximize the likelihood.
  \item<+-> To gain experience carrying out statistical investigations using iterated filtering in a relatively simple situation: fitting an SIR model to data from a measles outbreak.
  \end{enumerate}
\end{frame}

\AtBeginSection[]{
  \begin{frame}<beamer>
    \frametitle{Outline}
    \tableofcontents[currentsection]
  \end{frame}
}

\section{Classification of statistical methods for POMP models}

\begin{frame}{Classification of statistical methods for POMP models}
  \begin{itemize}
  \item Many, many statistical methods have been proposed for inference on POMP models \citep{He2010,King2016}.
  \item The volume of research indicates both the importance and the difficulty of the problem.
  \item Let's start by considering three criteria to categorize inference methods:
    \begin{itemize}
    \item the plug-and-play property
    \item full-information or feature-based
    \item frequentist or Bayesian
    \end{itemize}
  \end{itemize}
\end{frame}

\subsection{The plug-and-play property}

\begin{frame}[allowframebreaks=0.7]{Plug-and-play (also called simulation-based) methods}
  \begin{itemize}
  \item Inference methodology that calls \code{rprocess} but not \code{dprocess} is said to be \emph{plug-and-play}.
    All popular modern Monte Carlo methods fall into this category. 
  \item ``Simulation-based'' is equivalent to ``plug-and-play''. 
  \item Historically, simulation-based meant simulating forward from initial conditions to the end of the time series. 
  \item However, particle filtering methods instead consider each observation interval sequentially.
    They carry out multiple, carefully selected, simulations over each interval.
  \item Plug-and-play methods can call \code{dmeasure}.
    A method that uses only \code{rprocess} and \code{rmeasure} is called ``doubly plug-and-play''.
  \item Two \emph{non-plug-and-play} methods---expectation-maximization (EM) and Markov chain Monte Carlo (MCMC)---have theoretical convergence problems for nonlinear POMP models.
    The failures of these two workhorses of statistical computation have prompted development of alternative methodologies.
  \end{itemize}
\end{frame}

\subsection{Full information vs.~feature-based methods}

\begin{frame}[allowframebreaks=0.7]
  \frametitle{Full-information and feature-based methods}  
  \begin{itemize}
  \item \emph{Full-information} methods are defined to be those based on the likelihood function for the full data (i.e., likelihood-based frequentist inference and Bayesian inference).
  \item \emph{Feature-based} methods either consider a summary statistic (a function of the data) or work with an an alternative to the likelihood.
  \item Asymptotically, full-information methods are statistically efficient and feature-based methods are not.
  \item In some cases, loss of statistical efficiency might be an acceptable tradeoff for advantages in computational efficiency.
  \item However:
    \begin{itemize}
    \item Good low-dimensional summary statistics can be hard to find. 
    \item When using statistically inefficient methods, it can be hard to know how much information you are losing. 
    \item Intuition and scientific reasoning can be inadequate tools to derive informative low-dimensional summary statistics \citep{shrestha11,ionides11-statSci}.
    \end{itemize}
  \end{itemize}
\end{frame}

\subsection{Bayesian vs.~frequentist approaches}

\begin{frame}[allowframebreaks=0.7]
  \frametitle{Bayesian and frequentist methods}
  \begin{itemize}
  \item Recently, plug-and-play Bayesian methods have been discovered:
    \begin{itemize}
    \item particle Markov chain Monte Carlo (PMCMC) \citep{Andrieu2010}.
    \item  approximate Bayesian computation (ABC) \citep{Toni2009}.
    \end{itemize}
  \item Prior belief specification is both the strength and weakness of Bayesian methodology:
  \item The likelihood surface for nonlinear POMP models often contains nonlinear ridges and variations in curvature. 
  \item These situations bring into question the appropriateness of independent priors derived from expert opinion on marginal distributions of parameters.
  \item They also are problematic for specification of ``flat'' or ``uninformative'' prior beliefs.
  \item Expert opinion can be treated as data for non-Bayesian analysis.
    However, our primary task is to identify the information in the data under investigation, so it can be helpful to use methods that do not force us to make our conclusions dependent on quantification of prior beliefs.
  \end{itemize}
\end{frame}

\subsection*{Summary}

\begin{frame}
  \frametitle{POMP inference methodologies}
  \begin{tabular}{| l | l | l |}
    \hline\hline
    &Frequentist &Bayesian\\
    \hline
    \multicolumn{3}{| c |}{Plug-and-play}\\
    \hline
    Full-information & iterated filtering &particle MCMC\\
    \hline
    Feature-based &simulated moments &ABC\\
    &synthetic likelihood (SL) &SL-based MCMC\\
    &nonlinear forecasting &\\
    \hline
    \multicolumn{3}{| c |}{Not plug-and-play}\\
    \hline
    Full-information & EM algorithm &MCMC\\
    &Kalman filter & \\
    \hline
    Feature-based & Yule-Walker\footnote{Yule-Walker is a method of moments for ARMA, a linear Gaussian POMP.} &extended Kalman filter\footnote{The Kalman filter gives the exact likelihood for a linear Gaussian POMP. The extended Kalman filter gives an approximation for nonlinear models that can be used for quasi-likelihood or quasi-Bayesian inference.\label{fn:kf}}\\
    &extended Kalman filter\textsuperscript{\ref{fn:kf}} & \\
    \hline\hline
  \end{tabular}
\end{frame}

\section{Iterated filtering in theory}

\begin{frame}{Full-information, plug-and-play, frequentist methods}
  \begin{itemize}
  \item Iterated filtering methods \citep{ionides06,ionides15} are the only currently available, full-information, plug-and-play, frequentist methods for POMP models.
  \item Iterated filtering methods have been shown to solve likelihood-based inference problems for epidemiological situations which are computationally intractable for available Bayesian methodology \citep{ionides15}.
  \end{itemize}
\end{frame}

\begin{frame}{An iterated filtering algorithm (IF2)}

  We focus on the IF2 algorithm of \citet{ionides15}.
  In this algorithm:

  \begin{itemize}
  \item Each iteration consists of a particle filter, carried out with the parameter vector, for each particle, doing a random walk.
  \item At the end of the time series, the collection of parameter vectors is recycled as starting parameters for the next iteration.
  \item The random-walk variance decreases at each iteration.
  \end{itemize}

  In theory, this procedure converges toward the region of parameter space maximizing the maximum likelihood.  
  In practice, we can test this claim on examples.
\end{frame}

\begin{frame}{IF2 algorithm pseudocode}

  \textbf{Input:}
  \begin{itemize}
  \item simulators for $f_{X_0}(x_0;\theta)$ and $f_{X_n|X_{n-1}}(x_n| x_{n-1}; \theta)$;\\
  \item evaluator for $f_{Y_n|X_n}(y_n| x_n;\theta)$;\\
  \item data, $y^*_{1:N}$\\
  \end{itemize}

  \textbf{Algorithmic parameters:}
  \begin{itemize}
  \item number of iterations, $M$;\\
  \item number of particles, $J$;\\
  \item initial parameter swarm, $\{\Theta^0_j, j=1,\dots,J\}$;\\
  \item perturbation density, $h_n(\theta|\varphi;\sigma)$;\\
  \item perturbation scale, $\sigma_{1{:}M}$\\
  \end{itemize}

  \textbf{Output:}
  \begin{itemize}
  \item final parameter swarm, $\{\Theta^M_j, j=1,\dots,J\}$\\
  \end{itemize}
\end{frame}

\begin{frame}{IF2 algorithm pseudocode II}
  \textbf{Procedure:}
  \begin{enumerate}
  \item For $m$ in $1{:}M$
  \item $\qquad$ $\Theta^{F,m}_{0,j}\sim h_0(\theta|\Theta^{m-1}_{j}; \sigma_m)$ for $j$ in $1{:} J$
  \item $\qquad$ $X_{0,j}^{F,m}\sim f_{X_0}(x_0 ; \Theta^{F,m}_{0,j})$ for $j$ in $1{:} J$
  \item $\qquad$ For $n$ in $1{:} N$
  \item $\qquad\qquad$ $\Theta^{P,m}_{n,j}\sim h_n(\theta|\Theta^{F,m}_{n-1,j},\sigma_m)$ for $j$ in $1{:} J$
  \item $\qquad\qquad$ $X_{n,j}^{P,m}\sim f_{X_n|X_{n-1}}(x_n | X^{F,m}_{n-1,j}; \Theta^{P,m}_{n,j})$ for $j$ in $1{:} J$
  \item $\qquad\qquad$ $w_{n,j}^m = f_{Y_n|X_n}(y^*_n| X_{n,j}^{P,m} ; \Theta^{P,m}_{n,j})$ for $j$ in $1{:} J$
  \item $\qquad\qquad$ Draw $k_{1{:}J}$ with $P[k_j=i]=  w_{n,i}^m\Big/\sum_{u=1}^J w_{n,u}^m$
  \item $\qquad\qquad$ $\Theta^{F,m}_{n,j}=\Theta^{P,m}_{n,k_j}$ and $X^{F,m}_{n,j}=X^{P,m}_{n,k_j}$ for $j$ in $1{:} J$
  \item $\qquad$ End For
  \item $\qquad$ Set $\Theta^{m}_{j}=\Theta^{F,m}_{N,j}$ for $j$ in $1{:} J$
  \item End For
  \end{enumerate}
\end{frame}

\begin{frame}{IF2 algorithm pseudocode III}
  \textbf{Remarks:}
  \begin{itemize}
  \item The $N$ loop (lines 4 through 10) is a basic particle filter applied to a model with stochastic perturbations to the parameters.
  \item The $M$ loop repeats this particle filter with decreasing perturbations.
  \item The superscript $F$ in $\Theta^{F,m}_{n,j}$ and $X^{F,m}_{n,j}$ denote solutions to the \emph{filtering problem}, with the particles $j=1,\dots,J$ providing a Monte Carlo representation of the conditional distribution at time $n$ given data $y^*_{1:n}$ for filtering iteration $m$.
  \item The superscript $P$ in $\Theta^{P,m}_{n,j}$ and $X^{P,m}_{n,j}$ denote solutions to the \emph{prediction problem}, with the particles $j=1,\dots,J$ providing a Monte Carlo representation of the conditional distribution at time $n$ given data $y^*_{1:n-1}$ for filtering iteration $m$.
  \item The \emph{weight} $w^m_{n,j}$ gives the likelihood of the data at time $n$ for particle $j$ in filtering iteration $m$.
  \end{itemize}
\end{frame}

\begin{frame}{Analogy with evolution by natural selection}
  \begin{itemize}
  \item The parameters characterize the \emph{genotype}.
  \item The swarm of particles is a \emph{population}.
  \item The likelihood, a measure of the compatibility between the parameters and the data, is the analogue of \emph{fitness}.
  \item Each successive observation is a new \emph{generation}.
  \item Since particles reproduce in each generation in proportion to their likelihood, the particle filter acts like \emph{natural selection}.
  \item The artificial perturbations augment the ``genetic'' variance and therefore correspond to \emph{mutation}.
  \item IF2 increases the \emph{fitness} of the population of particles.
  \item However, because our scientific interest focuses on the model without the artificial perturbations, we decrease the intensity of the latter with successive iterations.
  \end{itemize}
\end{frame}

\section{Iterated filtering in practice}

\subsection{An example problem}

\begin{frame}[fragile]
  \frametitle{Applying IF2 to the Consett measles outbreak}

  To apply IF2 to a relatively simple epidemiological example, we consider fitting a stochastic SIR model to data from a measles outbreak in the small English town of Consett.

  Reports consist of the number of cases for each week of the year.

  The population of the town was approximately 38,000 and, since the outbreak is confined to less than one year, we will ignore births and deaths.

  The data are available on the course website:

  <<load_data>>=
  library(tidyverse)

  courseurl <- "https://kingaa.github.io/sbied/"
  datafile <- "mif/Measles_Consett_1948.csv"

  read_csv(paste0(courseurl,datafile)) %>%
    select(week,reports=cases) %>%
    filter(week<=42) -> dat
  @
\end{frame}

\begin{frame}[fragile]
  \frametitle{Applying IF2 to the Consett measles outbreak II}
  <<plot_data,out.width="0.8\\textwidth">>=
  dat %>%
    ggplot(aes(x=week,y=reports))+
    geom_line()
  @
\end{frame}

\begin{frame}[allowframebreaks=0.85,fragile]
  \frametitle{Stochastic SIR model}
  
  <<sir-diagram,echo=FALSE,purl=FALSE,fig.height=3/4,fig.width=6>>=
  library(grid)
  vp <- viewport(width=unit(0.95,"npc"),height=unit(0.95,"npc"))
  pushViewport(vp)
  grid.rect(x=c(1/4,2/4,3/4),y=1/2,width=1/8,height=1,just=c(0.5,0.5),gp=gpar(fill="white",lwd=2))
  grid.text(x=c(1/4,2/4,3/4),y=1/2,label=c(expression(S),expression(I),expression(R)),gp=gpar(fontsize=24))
  grid.text(x=unit(c(6/16,10/16),"npc"),y=unit(1/2,"npc")+unit(c(12,-12),"point"),
            label=c(expression(mu[SI]),expression(mu[IR])),gp=gpar(fontsize=18))
  grid.lines(x=c(5/16,7/16),y=1/2,arrow=arrow(length=unit(0.1,"npc")),gp=gpar(lwd=2))
  grid.lines(x=c(9/16,11/16),y=1/2,arrow=arrow(length=unit(0.1,"npc")),gp=gpar(lwd=2))
  popViewport()
  @

  \begin{itemize}
  \item Our model is a variation on a basic SIR Markov chain
  \item State: $X(t)=(S(t),I(t),R(t))$; numbers of hosts in susceptible, infectious, and recovered classes.
  \item Assume: a single infection in week 0, i.e., that $I(0)=1$.
  \item Markov transmission model:
    \begin{itemize}
    \item Each individual in $S$ transitions to $I$ at rate $\mu_{SI}=\beta\,I(t)/N$.
    \item Each individual in $I$ transitions at rate $\mu_{IR}$ to $R$.
    \item $1/\mu_{IR}$ is the mean infectious period.
    \end{itemize}
  \item All rates will have units wk\textsuperscript{-1}.
  \item This model has limitations and weaknesses, but writing down and fitting a model is a starting point for data analysis, not an end point.
  \item In particular, having fit one model, one should certainly examine alternative models.
  \item For example, one could include a latency period for infections, or one could modify the model to give a better description of the diagnosis, bed-confinement, and convalescence processes.
  \item Notice that we do not need to track $R$ since this variable has consequences neither for the dynamics of the state process nor for the data.
  \end{itemize}
\end{frame}

\begin{frame}[fragile,allowframebreaks]
  \frametitle{Implementation in \package{pomp}}

  As before, we code the model using C snippets

  <<csnippets>>=
  library(tidyverse)
  library(pomp)

  sir_step <- Csnippet("
  double dN_SI = rbinom(S,1-exp(-Beta*I/N*dt));
  double dN_IR = rbinom(I,1-exp(-mu_IR*dt));
  S -= dN_SI;
  I += dN_SI - dN_IR;
  H += dN_IR;
  ")
  @
  
  \framebreak

  The \code{rinit} component:
  <<sir_init>>=
  sir_init <- Csnippet("
  S = nearbyint(eta*N);
  I = 1;
  H = 0;
  ")
  @
  
  The measurement model:
  <<sir_measure_model>>=
  dmeas <- Csnippet("
  lik = dbinom(reports,H,rho,give_log);
  ")

  rmeas <- Csnippet("
  reports = rbinom(H,rho);
  ")
  @ 
  
  \framebreak

  <<sir_pomp_construct>>=
  dat %>%
    pomp(
      times="week",t0=0,
      rprocess=euler(sir_step,delta.t=1/7),
      rinit=sir_init,
      rmeasure=rmeas,
      dmeasure=dmeas,
      accumvars="H",
      statenames=c("S","I","H"),
      paramnames=c("Beta","mu_IR","eta","rho","N")
    ) -> measSIR
  @ 
\end{frame}


%% Note that, in our measurement model, we've added a small positive number ($10^{-6}$) to the expected number of cases.
%% Why is this useful?
%% What complications does it introduce in the interpretation of results?

%% Note that we've included parameter transformations (\code{partrans}) in \code{measSIR}.
%% The reason for this will become clear soon.
%%    partrans=parameter_trans(log=c("Beta","mu_IR"),logit=c("rho","eta")),

\begin{frame}[fragile]
  \frametitle{Testing the codes}
  To develop and debug code, it is useful to have testing codes that run quickly and fail if the codes are not working correctly.

  As such a test, here we run some simulations and a particle filter.

  We'll use the following parameters, derived from our earlier explorations:
  
  <<start_params>>=
  params <- c(Beta=20,mu_IR=2,rho=0.5,eta=0.1,N=38000)
  @
\end{frame}

\begin{frame}[fragile,allowframebreaks=0.7]
  \frametitle{Testing the codes: simulation}
  Now to run and plot some simulations:
  <<init_sim>>=
  measSIR %>%
    simulate(params=params,nsim=10,format="data.frame") -> y
  @
  <<init_sim_plot,purl=FALSE,out.width="0.8\\textwidth">>=
  y %>%
    ggplot(aes(x=week,y=reports,group=.id,color=factor(.id)))+
    geom_line()+
    scale_color_brewer(type="qual",palette=3)+
    guides(color=FALSE)
  @ 
\end{frame}

\begin{frame}[fragile,allowframebreaks=0.9]
  \frametitle{Testing the codes: filtering}
  Before engaging in iterated filtering, it is a good idea to check that the basic particle filter is working since we can't iterate something unless we can run it once!
  The simulations above check the \code{rprocess} and \code{rmeasure} codes;
  the particle filter depends on the \code{rprocess} and \code{dmeasure} codes and so is a check of the latter.
  
  <<init_pfilter>>=
  measSIR %>%
    pfilter(Np=1000,params=params) -> pf
  @
  <<init_pfilter_plot,purl=F,dpi=200,out.width="0.7\\textwidth">>=
  plot(pf)
  @ 
  
  The above plot shows the data (\code{reports}), along with the \emph{effective sample size} of the particle filter (\code{ess}) and the log likelihood of each observation conditional on the preceding ones (\code{cond.logLik}).
\end{frame}

\subsection{Setting up the estimation problem}

\begin{frame}[fragile]
  \frametitle{Setting up the estimation problem}

  Let's assume that the population size, $N$, is known accurately.
  We'll fix that parameter.

  Let's also imagine that we have access to the results of household and clinical studies that have concluded that infected patients shed the virus for 3--4~da.
  We'll use these results to constrain the infectious period in our model to 3.5~da, i.e., $\mu_{IR}=2~\mathrm{wk}^{-1}$.
  Later, we'll relax this assumption.
  
  <<fixed_params>>=
  fixed_params <- c(N=38000, mu_IR=2)
  @
  
  We proceed to estimate $\beta$, $\eta$, and $\rho$.
\end{frame}

\begin{frame}[fragile,allowframebreaks=0.8]
  \frametitle{Parallel computing}
  It will be helpful to parallelize most of the computations.
  Most machines nowadays have multiple cores and using this computational capacity is as simple as:
  \begin{enumerate}[(i)]
  \item letting \Rlanguage know you plan to use multiple processors;
  \item using the parallel for loop provided by the \package{foreach} package; and
  \item paying proper attention to the use of parallel random number generators (RNG).
  \end{enumerate}
  For example:
  
  <<parallel-setup,cache=FALSE>>=
  library(foreach)
  library(doParallel)
  registerDoParallel()
  @ 
  
  The first two lines above load the \package{foreach} and \package{doParallel} packages, the latter being a ``backend'' for the \package{foreach} package.
  The next line tells \package{foreach} that we will use the \package{doParallel} backend.
  By default, \Rlanguage will guess how many cores are available and will run about half this number of concurrent \Rlanguage processes.
\end{frame}

\begin{frame}[fragile]{Parallel random number generators (RNG)}
  To initialize a parallel RNG, we use the \package{doRNG} package.
  The following ensures that the parallel computations will be both mutually independent and reproducible.
  
  <<pf1,eval=FALSE,purl=FALSE>>=
  library(doRNG)
  registerDoRNG(625904618)
  @ 
\end{frame}

\begin{frame}[fragile]
  \frametitle{Running a particle filter}

  We proceed to carry out replicated particle filters at an initial guess of $\beta=\Sexpr{params["Beta"]}$, $\eta=\Sexpr{params["eta"]}$, and $\rho=\Sexpr{params["rho"]}$.
  
  <<pf2,eval=FALSE,purl=FALSE>>=
  foreach(i=1:10,.combine=c) %dopar% {
    library(pomp)
    measSIR %>% pfilter(params=params,Np=10000)
  } -> pf

  pf %>% logLik() %>% logmeanexp(se=TRUE) -> L_pf
  L_pf
  @ 

  <<pf,echo=FALSE>>=
  <<pf1>>
  tic <- Sys.time()
  <<pf2>>
  toc <- Sys.time()
  @

  In \Sexpr{round(toc-tic,2)} seconds, using \Sexpr{min(getDoParWorkers(),length(pf))} cores, we obtain an unbiased likelihood estimate of \Sexpr{round(L_pf[1],1)} with a Monte Carlo standard error of \Sexpr{signif(L_pf[2],2)}.
\end{frame}

\begin{frame}[fragile,allowframebreaks=0.7]{Building up a picture of the likelihood surface}

  \begin{itemize}
  \item Given a model and a set of data, the likelihood surface is well defined, though it may be difficult to visualize.
  \item We can develop a progressively more complete picture of this surface by storing likelihood estimates whenever we compute them.
  \item It is a very good idea to set up a database within which to store the likelihood of every point for which we have an estimated likelihood.
  \item This will become larger and more complete as our parameter-space search goes on and will be a basis for a variety of explorations.
  \end{itemize}

  At this point, we've computed the likelihood at a single point.
  Let's store this point, together with the estimated likelihood and our estimate of the standard error on that likelihood, in a CSV file:
  <<init_csv,cache=FALSE>>=
  pf[[1]] %>% coef() %>% bind_rows() %>%
    bind_cols(loglik=L_pf[1],loglik.se=L_pf[2]) %>%
    write_csv("measles_params.csv")
  @
\end{frame}

\subsection{A local search of the likelihood surface}

\begin{frame}[fragile,allowframebreaks=0.9]{A local search of the likelihood surface}
  
  Let's carry out a local search using \code{mif2} around this point in parameter space. 

  \begin{itemize}
  \item We need to choose the \code{rw.sd} and \code{cooling.fraction.50} algorithmic parameters.
  \item Since $\beta$ and $\mu_{IR}$ will be estimated on the log scale, and we expect that multiplicative perturbations of these parameters will have roughly similar effects on the likelihood, we'll use a perturbation size of $0.02$, which we imagine will have a small but non-negligible effect.
  \item For simplicity, we'll use the same perturbation size on $\rho$.
  \item We fix \code{cooling.fraction.50=0.5}, so that after 50 \code{mif2} iterations, the perturbations are reduced to half their original magnitudes.
  \end{itemize}
  
  <<local_search,eval=FALSE,purl=FALSE>>=
  foreach(i=1:20,.combine=c) %dopar% {
    library(pomp)
    library(tidyverse)
    measSIR %>%
      mif2(
        params=params,
        Np=2000, Nmif=50,
        partrans=parameter_trans(
          log=c("Beta"),
          logit=c("rho","eta")
        ),
        paramnames=c("Beta","rho","eta"),
        cooling.fraction.50=0.5,
        rw.sd=rw.sd(Beta=0.02, rho=0.02, eta=ivp(0.02))
      )
  } -> mifs_local
  @ 
  <<local_search_eval,echo=FALSE>>=
  registerDoRNG(482947940)
  bake(file="local_search.rds",{
    <<local_search>>
    attr(mifs_local,"ncpu") <- getDoParWorkers()
    mifs_local
  }) -> mifs_local
  t_loc <- attr(mifs_local,"system.time")
  ncpu_loc <- attr(mifs_local,"ncpu")
  @
\end{frame}

\begin{frame}[fragile]{Windows issues}
  \textbf{NB:} Some Windows users have reported trouble with the above code.
  This appears to be due to certain Windows security features.
  It has been possible to circumvent this problem by adding \code{cdir="."} and \code{cfile=<filename>} as arguments in the call that created \code{measSIR}.
  Thus, for example,
  
  <<eval=FALSE,purl=FALSE>>=
  dat %>%
    pomp(
      times="week",t0=0,
      rprocess=euler(sir_step,delta.t=1/7),
      rinit=sir_init, rmeasure=rmeas, dmeasure=dmeas,
      partrans=parameter_trans(log="Beta",logit=c("rho","eta")),
      accumvars="H", statenames=c("S","I","H"),
      paramnames=c("Beta","mu_IR","eta","rho","N"),
      cdir=".", cfile="measSIR"
    ) -> measSIR
  @

\end{frame}

\begin{frame}[fragile,allowframebreaks]{Iterated filtering diagnostics}
  We obtain some diagnostic plots with the \code{plot} command applied to \code{mifs\_local}.
  Here is a way to get a prettier version:
  
  <<local_search_plot,out.height="0.7\\textheight">>=
  mifs_local %>%
    traces() %>%
    melt() %>%
    ggplot(aes(x=iteration,y=value,group=L1,color=factor(L1)))+
    geom_line()+
    guides(color=FALSE)+
    facet_wrap(~variable,scales="free_y")+
    theme_bw()
  @
  
  \framebreak

  \begin{itemize}
  \item We see that the likelihood eventually increases as the iterations proceed, though there is considerable variability due to
    \begin{enumerate}[(a)]
    \item the poorness of our starting guess and
    \item the stochastic nature of this Monte Carlo algorithm.
    \end{enumerate}
  \item We see movement in the parameters, though considerable variability remains.
  \end{itemize}
\end{frame}

\begin{frame}[fragile,allowframebreaks]{Estimating the likelihood}
  Although the filtering carried out by \code{mif2} in the final filtering iteration generates an approximation to the likelihood at the resulting point estimate, this is not good enough for reliable inference.
  \begin{itemize}
  \item Partly, this is because parameter perturbations are applied in the last filtering iteration, so that the likelihood reported by \code{mif2} is not identical to that of the model of interest.
  \item Partly, this is because \code{mif2} is usually carried out with fewer particles than are needed for a good likelihood evaluation.
  \end{itemize}
  Therefore, we evaluate the likelihood, together with a standard error, using replicated particle filters at each point estimate.
  
  <<lik_local,eval=FALSE,purl=FALSE>>=
  foreach(mf=mifs_local,.combine=rbind) %dopar% {
    library(pomp)
    library(tidyverse)
    evals <- replicate(10, logLik(pfilter(mf,Np=20000)))
    ll <- logmeanexp(evals,se=TRUE)
    mf %>% coef() %>% bind_rows() %>%
      bind_cols(loglik=ll[1],loglik.se=ll[2])
  } -> results
  @
  
  <<lik_local_eval,include=FALSE>>=
  registerDoRNG(900242057)
  bake(file="lik_local.rds",{
    <<lik_local>>
    attr(results,"ncpu") <- getDoParWorkers()
    results
  }) -> results
  t_local <- attr(results,"system.time")
  ncpu_local <- attr(results,"ncpu")
  @
  
  On \Sexpr{ncpu_local} processors, this local investigation took \Sexpr{round(t_loc[3],0)}~sec for the maximization and \Sexpr{round(t_local[3],0)}~sec for the likelihood evaluation.
  
  \framebreak
  
  These repeated stochastic maximizations can also show us the geometry of the likelihood surface in a neighborhood of this point estimate:

  <<pairs_local,fig.width=6,fig.height=6,dpi=200,out.width="0.7\\textwidth">>=
  pairs(~loglik+Beta+eta+rho,data=results,pch=16)
  @

\end{frame}

\begin{frame}[fragile]{Building up a picture of the likelihood surface}
  This plot shows a hint of a ridge in the likelihood surface (cf.~the $\beta$-$\eta$ panel).
  However, the sampling is as yet too sparse to give a clear picture.

  We add these newly explored points to our database,

  <<local_database,cache=FALSE>>=
  read_csv("measles_params.csv") %>%
    bind_rows(results) %>%
    arrange(-loglik) %>%
    write_csv("measles_params.csv")
  @

  and move on to a more thorough exploration of the likelihood surface.
\end{frame}

\subsection{A global search}

\begin{frame}[fragile,allowframebreaks]
  \frametitle{A global search of the likelihood surface}

  \begin{itemize}
  \item When carrying out parameter estimation for dynamic systems, we need to specify beginning values for both the dynamic system (in the state space) and the parameters (in the parameter space).
  \item To avoid confusion, we use the term ``initial values'' to refer to the state of the system at $t_0$ and ``starting values'' to refer to the point in parameter space at which a search is initialized.
  \item Practical parameter estimation involves trying many starting values for the parameters.
  \item One way to approach this is to choose a large box in parameter space that contains all remotely sensible parameter vectors.
  \item If an estimation method gives stable conclusions with starting values drawn randomly from this box, this gives some confidence that an adequate global search has been carried out. 
  \end{itemize}

  \framebreak

  For our measles model, a box containing reasonable parameter values might be
  $\beta\in (10,80)$, $\rho\in (0.2,0.9)$, $\eta\in (0,0.2)$.

  We are now ready to carry out likelihood maximizations from diverse starting points.

  <<cluster_setup,include=FALSE,purl=TRUE>>=
  if (file.exists("CLUSTER.R")) {
    source("CLUSTER.R")
  }
  @
  
  <<global_search1>>=
  set.seed(2062379496)

  runifDesign(
    lower=c(Beta=5,rho=0.2,eta=0),
    upper=c(Beta=80,rho=0.9,eta=0.4),
    nseq=300
  ) -> guesses

  mf1 <- mifs_local[[1]]
  @
  
  <<global_search2,eval=FALSE,purl=FALSE>>=
  registerDoRNG(1270401374)
  foreach(guess=iter(guesses,"row"), .combine=rbind) %dopar% {
    library(pomp)
    library(tidyverse)
    mf1 %>%
      mif2(params=c(unlist(guess),fixed_params)) %>%
      mif2(Nmif=100) -> mf
    replicate(
      10,
      mf %>% pfilter(Np=100000) %>% logLik()
    ) %>%
      logmeanexp(se=TRUE) -> ll
    mf %>% coef() %>% bind_rows() %>%
      bind_cols(loglik=ll[1],loglik.se=ll[2])
  } -> results
  @ 
  <<global_search_eval,include=FALSE>>=
  bake(file="global_search.rds",{
    <<global_search2>>
    attr(results,"ncpu") <- getDoParWorkers()
    results
  }) -> results
  t_global <- attr(results,"system.time")
  ncpu_global <- attr(results,"ncpu")
  @ 
  <<cache=FALSE,include=FALSE>>=
  read_csv("measles_params.csv") %>%
    bind_rows(results) %>%
    filter(is.finite(loglik)) %>%
    arrange(-loglik) %>%
    write_csv("measles_params.csv")
  @ 
  
  \begin{itemize}
  \item The above codes run one search from each of \Sexpr{nrow(guesses)} starting values.
  \item Each search consists of an initial run of \Sexpr{nrow(traces(mf1))-1} IF2 iterations, followed by another 100 iterations.
  \item These codes exhibit a general \package{pomp} behavior:
    \begin{itemize}
    \item Re-running a command on an object (i.e., \code{mif2} on \code{mf1}) created by the same command preserves the algorithmic arguments.
    \item In particular, running \code{mif2} on the result of a \code{mif2} computation re-runs IF2 from the endpoint of the first run.
    \item In the second computation, by default, all algorithmic parameters are preserved;
      here we overrode the default choice of \code{Nmif}.
    \end{itemize}
  \item Following the \code{mif2} computations, the particle filter is used to evaluate the likelihood, as before.
  \end{itemize}

  \framebreak

  \begin{itemize}
  \item In contrast to the local-search codes above, here we return only the endpoint of the search, together with the likelihood estimate and its standard error in a named vector.
  \item The best result of this search had a likelihood of \Sexpr{round(max(results$loglik),1)} with a standard error of \Sexpr{round(results$loglik.se[which.max(results$loglik)],2)}.
  \item This took \Sexpr{round(t_global["elapsed"]/60,1)} minutes altogether using \Sexpr{ncpu_global} processors.
  \end{itemize}

  \framebreak
  
  Again, we attempt to visualize the global geometry of the likelihood surface using a scatterplot matrix.
  In particular, here we plot both the starting values (grey) and the IF2 estimates (red).

  <<pairs_global1>>=
  read_csv("measles_params.csv") %>%
    filter(loglik>max(loglik)-50) %>%
    bind_rows(guesses) %>%
    mutate(type=if_else(is.na(loglik),"guess","result")) %>%
    arrange(type) -> all

  pairs(~loglik+Beta+eta+rho, data=all,
        col=ifelse(all$type=="guess",grey(0.5),"red"),pch=16)
  @

  \framebreak

  \begin{itemize}
  \item We see that optimization attempts from diverse remote starting points converge on a particular region in parameter space.
  \item The estimates have comparable likelihoods, despite their considerable variability.
  \item This gives us some confidence in our maximization procedure. 
  \end{itemize}
  \framebreak

  The projections of the estimates give us ``poor man's profiles'':

  <<pairs_global2>>=
  all %>%
    filter(type=="result") %>%
    filter(loglik>max(loglik)-10) %>%
    ggplot(aes(x=eta,y=loglik))+
    geom_point()+
    labs(
      x=expression("eta"),
      title="poor man's profile likelihood"
    )
  @
\end{frame}

\subsection{Profile likelihood}

\begin{frame}[fragile,allowframebreaks]{Profile likelihood over $\eta$}

  \begin{itemize}
  \item The curvature displayed in the upper envelope of the above plot suggests that there is indeed information in the data with respect to the susceptible fraction, $\eta$.
  \item To solidify this evidence, let's compute a profile likelihood over this parameter.
  \item Recall that this means determining, for each value of $\eta$, the best likelihood that the model can achieve.
  \item To do this, we'll first bound the uncertainty by putting a box around the highest-likelihood estimates we've found so far.
  \item Within this box, we'll choose some random starting points, for each of several values of $\eta$.
  \end{itemize}

  \framebreak
  
  <<eta_profile1a>>=
  read_csv("measles_params.csv") %>%
    filter(loglik>max(loglik)-20,loglik.se<2) %>%
    sapply(range) -> box
  box
  @
  
  <<eta_profile1b>>=
  set.seed(1196696958)
  profileDesign(
    eta=seq(0.01,0.85,length=40),
    lower=box[1,c("Beta","rho")],
    upper=box[2,c("Beta","rho")],
    nprof=15, type="runif"
  ) -> guesses
  plot(guesses)
  @
  
  \framebreak

  \begin{itemize}
  \item Now, we'll start one independent sequence of iterated filtering operations from each of these points.
  \item We'll be careful to keep $\eta$ fixed.
  \item This is accomplished by not giving this parameter a random perturbation in the \code{mif2} call.
  \end{itemize}
  
  \framebreak

  <<eta_profile2,eval=FALSE,purl=FALSE>>=
  foreach(guess=iter(guesses,"row"), .combine=rbind) %dopar% {
    library(pomp)
    library(tidyverse)
    mf1 %>%
      mif2(params=c(unlist(guess),fixed_params),
           rw.sd=rw.sd(Beta=0.02,rho=0.02)) %>%
      mif2(Nmif=100,cooling.fraction.50=0.3) -> mf
    replicate(
      10,
      mf %>% pfilter(Np=100000) %>% logLik()) %>%
      logmeanexp(se=TRUE) -> ll
    mf %>% coef() %>% bind_rows() %>%
      bind_cols(loglik=ll[1],loglik.se=ll[2])
  } -> results
  @
  
  <<eta_profile2_eval,include=FALSE>>=
  mf1 <- mifs_local[[1]]
  registerDoRNG(830007657)
  bake(file="eta_profile.rds",{
    <<eta_profile2>>
    attr(results,"ncpu") <- getDoParWorkers()
    results
  }) -> results
  t_eta <- attr(results,"system.time")
  ncpu_eta <- attr(results,"ncpu")
  @
\end{frame}

\begin{frame}[fragile,allowframebreaks]{Visualizing profile likelihood}

  As always, we save the results in our global database and plot the results.

  <<eta_profile_database,cache=FALSE>>=
  read_csv("measles_params.csv") %>%
    bind_rows(results) %>%
    filter(is.finite(loglik)) %>%
    arrange(-loglik) %>%
    write_csv("measles_params.csv")
  @
  
  <<eta_profile_pairs>>=
  read_csv("measles_params.csv") %>%
    filter(loglik>max(loglik)-10) -> all

  pairs(~loglik+Beta+eta+rho,data=all,pch=16)
  @
  
  \framebreak

  Plotting just the results of the profile calculation reveals that, while some of the IF2 runs either become ``stuck'' on local minima or run out of opportunity to reach the heights of the likelihood surface, many of the runs converge on high likelihoods.

  <<eta_profile_plot1>>=
  results %>%
    ggplot(aes(x=eta,y=loglik))+
    geom_point()
  @
  
  \framebreak

  A closer look shows what at first appears to be quite a flat surface over much of the explored range of $\eta$.
  Note that this appearance is due to the vertical scale, which is driven by the very low likelihoods associated with the smallest values of $\eta$.

  <<eta_profile_plot2>>=
  results %>%
    filter(is.finite(loglik)) %>%
    group_by(round(eta,5)) %>%
    filter(rank(-loglik)<3) %>%
    ungroup() %>%
    filter(loglik>max(loglik)-20) %>%
    ggplot(aes(x=eta,y=loglik))+
    geom_point()
  @ 
  
  \framebreak

  Focusing on just the top of the surface shows that, in fact, one is able to estimate $\eta$ using these data.
  In the following plot, the cutoff for the 95\% confidence interval (CI) is shown.

  <<eta_profile_plot3>>=
  maxloglik <- max(results$loglik,na.rm=TRUE)
  ci.cutoff <- maxloglik-0.5*qchisq(df=1,p=0.95)

  results %>%
    filter(is.finite(loglik)) %>%
    group_by(round(eta,5)) %>%
    filter(rank(-loglik)<3) %>%
    ungroup() %>%
    ggplot(aes(x=eta,y=loglik))+
    geom_point()+
    geom_smooth(method="loess",span=0.25)+
    geom_hline(color="red",yintercept=ci.cutoff)+
    lims(y=maxloglik-c(5,0))
  @
  
  \framebreak

  \begin{itemize}
  \item As one varies $\eta$ across the profile, the model compensates by adjusting the other parameters.
  \item It can be very instructive to understand how the model does this.
  \item For example, how does the reporting efficiency, $\rho$, change as $\eta$ is varied?
  \item We can plot $\rho$ vs $\eta$ across the profile.
  \item This is called a \emph{profile trace}.
  \end{itemize}
  \framebreak

  <<eta_profile_eta_by_rho>>=
  results %>%
    filter(is.finite(loglik)) %>%
    group_by(round(eta,5)) %>%
    filter(rank(-loglik)<3) %>%
    ungroup() %>%
    mutate(in_ci=loglik>max(loglik)-1.92) %>%
    ggplot(aes(x=eta,y=rho,color=in_ci))+
    geom_point()+
    labs(
      color="inside 95% CI?",
      x=expression(eta),
      y=expression(rho),
      title="profile trace"
    )
  @
\end{frame}

\begin{frame}[fragile,allowframebreaks]{Profile over $\rho$}

  <<include=FALSE>>=
  results %>%
    filter(is.finite(loglik)) %>%
    filter(loglik>max(loglik)-0.5*qchisq(df=1,p=0.95)) %>%
    summarize(min=min(rho),max=max(rho)) -> rho_ci
  @
  
  While the above profile trace is suggestive that the 95\% CI for $\eta$ must be between roughly \Sexpr{signif(100*rho_ci$min,1)}\% and \Sexpr{signif(100*rho_ci$max,1)}\%, to confirm this, we should construct a proper profile likelihood over $\rho$.
  We do so now.

  This time, we will initialize the IF2 computations at points we have already established have high likelihoods.

  <<rho_profile1>>=
  read_csv("measles_params.csv") %>%
    group_by(cut=round(rho,2)) %>%
    filter(rank(-loglik)<=10) %>%
    ungroup() %>%
    select(-cut,-loglik,-loglik.se) -> guesses
  @
  
  \framebreak

  <<rho_profile2,eval=FALSE,purl=FALSE>>=
  foreach(guess=iter(guesses,"row"), .combine=rbind) %dopar% {
    library(pomp)
    library(tidyverse)
    mf1 %>%
      mif2(params=guess,
           rw.sd=rw.sd(Beta=0.02,eta=ivp(0.02))) %>%
      mif2(Nmif=100,cooling.fraction.50=0.3) %>%
      mif2() -> mf
    replicate(
      10,
      mf %>% pfilter(Np=100000) %>% logLik()) %>%
      logmeanexp(se=TRUE) -> ll
    mf %>% coef() %>% bind_rows() %>%
      bind_cols(loglik=ll[1],loglik.se=ll[2])
  } -> results
  @
  <<rho_profile_eval,include=FALSE>>=
  mf1 <- mifs_local[[1]]
  registerDoRNG(2105684752)
  bake(file="rho_profile.rds",{
    <<rho_profile2>>
    attr(results,"ncpu") <- getDoParWorkers()
    results
  }) -> results
  t_rho <- attr(results,"system.time")
  ncpu_rho <- attr(results,"ncpu")
  @
  <<include=FALSE,cache=FALSE>>=
  read_csv("measles_params.csv") %>%
    bind_rows(results) %>%
    filter(is.finite(loglik)) %>%
    arrange(-loglik) %>%
    write_csv("measles_params.csv")
  @ 
\end{frame}

\begin{frame}[fragile,allowframebreaks]{Profile over $\rho$: results}

  <<>>=
  results %>%
    filter(is.finite(loglik)) -> results

  pairs(~loglik+Beta+eta+rho,data=results,pch=16)
  @
  
  \framebreak

  <<>>=
  results %>%
    filter(loglik>max(loglik)-10,loglik.se<1) %>%
    group_by(round(rho,2)) %>%
    filter(rank(-loglik)<3) %>%
    ungroup() %>%
    ggplot(aes(x=rho,y=loglik))+
    geom_point()+
    geom_hline(
      color="red",
      yintercept=max(results$loglik)-0.5*qchisq(df=1,p=0.95)
    )
  @
  
  \framebreak

  <<rho_ci>>=
  results %>%
    filter(loglik>max(loglik)-0.5*qchisq(df=1,p=0.95)) %>%
    summarize(min=min(rho),max=max(rho)) -> rho_ci
  @
  
  The data appear to be consistent with reporting efficiencies in the \Sexpr{signif(100*rho_ci$min,2)}--\Sexpr{signif(100*rho_ci$max,2)}\% range (95\% CI).
\end{frame}

\begin{frame}[allowframebreaks=0.7]{Parameter estimates as model predictions}
  
  \begin{itemize}
  \item The estimated parameters are one kind of model prediction.
  \item When we can estimate parameters using other data, we can test these predictions.
  \item In the case of a highly contagious, immunizing childhood infection such as measles, we can obtain an estimate of the reporting efficiency, $\rho$ by simply regressing cumulative cases on cumulative births \citep{Anderson1991} over many years.
  \item When we do this for Consett, we see that the reporting efficiency is roughly 60\%.
  \item Since such a value makes the outbreak data quite unlikely, the prediction does not appear to be borne out.
  \item We can conclude that one or more of our model assumptions is inconsistent with the data.
  \item Let's revisit our assumption that the infectious period is known to be 0.5~wk.
  \item Indeed, it would not be surprising were we to find that the \emph{effective} infectious period, at the population scale, were somewhat shorter than the \emph{clinical} infectious period.
  \item For example, confinement of patients should reduce contact rates, and might therefore curtail the effective infectious period.
  \item To investigate this, we'll relax our assumption about the value of $\mu_{IR}$.
  \end{itemize}

\end{frame}

\subsection{Expanding the search}

\begin{frame}[fragile,allowframebreaks]{Expanding the search}

  To expand the search, we'll construct a random design of starting parameters as before.
  
  <<exp_global_search1>>=
  set.seed(55266255)
  runifDesign(
    lower=c(Beta=5,mu_IR=0.2,eta=0),
    upper=c(Beta=80,mu_IR=5,eta=0.4),
    nseq=1000
  ) %>%
    mutate(
      rho=0.6,
      N=38000
    ) -> guesses
  @

  \framebreak

  \begin{itemize}
  \item For each of these starting points, we'll run a series of IF2 computations.
  \item Since we have gained some experience applying \code{mif2} to this model and these data, we have some expectation about how much computation is required.
  \item In the following, we'll use a lot more computational power than we have so far.
  \end{itemize}

  \framebreak

  For each of the starting points, we'll first perform 100 IF2 iterations:

  <<exp_global_search2a,eval=FALSE,purl=FALSE>>=
  library(pomp)
  library(tidyverse)
  measSIR %>%
    mif2(params=guess, Np=2000, Nmif=100,
         cooling.fraction.50=0.5,
         partrans=parameter_trans(
           log=c("Beta","mu_IR"),
           logit="eta"), paramnames=c("Beta","mu_IR","eta"),
         rw.sd=rw.sd(Beta=0.02,mu_IR=0.02,eta=ivp(0.02))) -> mf
  @

  We use random perturbations of the same magnitude as before, taking care to transform the parameters we are estimating.

  \framebreak

  Next, we repeat the calculations several times.
  Each additional set of IF2 iterations restarts the previous calculation at its endpoint.

  <<exp_global_search2b,eval=FALSE,purl=FALSE>>=
  mf %>%
    mif2(Nmif=100) %>%
    mif2(Nmif=100) %>%
    mif2(Nmif=100) -> mf
  @

  \framebreak

  In each of the previous calculations, we have used a relatively high cooling fraction.
  We'll now reduce this gradually.

  <<exp_global_search2c,eval=FALSE,purl=FALSE>>=
  mf %>%
    mif2(Nmif=100,cooling.fraction.50=0.3) %>%
    mif2(Nmif=100,cooling.fraction.50=0.3) %>%
    mif2(Nmif=100,cooling.fraction.50=0.3) %>%
    mif2(Nmif=100,cooling.fraction.50=0.1) %>%
    mif2(Nmif=100,cooling.fraction.50=0.1) %>%
    mif2(Nmif=100,cooling.fraction.50=0.1) -> mf
  @ 
  
  \framebreak

  We wrap the above in a \code{foreach} loop as before and take care to evaluate the likelihood at each end-point using \code{pfilter}.

  See the \link{https://raw.githubusercontent.com/kingaa/sbied/master/mif/mif.R}{\Rlanguage code for this lesson} to see exactly how this is done.

  <<exp_global_search_eval,include=FALSE>>=
  registerDoRNG(610408798)
  bake(file="global_search2.rds",{
    foreach(guess=iter(guesses,"row"), .combine=rbind) %dopar% {
      <<exp_global_search2a>>
      <<exp_global_search2b>>
      <<exp_global_search2c>>
      replicate(
        10,
        mf %>% pfilter(Np=100000) %>% logLik()
      ) %>% logmeanexp(se=TRUE) -> ll
      mf %>% coef() %>% bind_rows() %>%
        bind_cols(loglik=ll[1],loglik.se=ll[2])
    } -> results
    attr(results,"ncpu") <- getDoParWorkers()
    results
  }) %>%
    filter(is.finite(loglik)) -> results
  t_expglob <- attr(results,"system.time")
  ncpu_expglob <- attr(results,"ncpu")
  @
  
  <<include=FALSE,cache=FALSE>>=
  read_csv("measles_params.csv") %>%
    bind_rows(results) %>%
    filter(is.finite(loglik)) %>%
    arrange(-loglik) %>%
    write_csv("measles_params.csv")
  @

  The computations above required \Sexpr{round(t_expglob["elapsed"]/60,1)} minutes on \Sexpr{ncpu_expglob} processors.
  
  <<>>=
  read_csv("measles_params.csv") %>%
    filter(loglik>max(loglik)-20) -> all

  pairs(~loglik+rho+mu_IR+Beta+eta,data=all,pch=16)
  @ 
  
  \framebreak

  <<>>=
  pairs(~loglik+rho+mu_IR+Beta+eta,data=results,pch=16)
  @ 

  \framebreak

  <<>>=
  results %>%
    filter(loglik>max(loglik)-20,loglik.se<1) %>%
    ggplot(aes(x=mu_IR,y=loglik))+
    geom_point()+
    geom_hline(
      color="red",
      yintercept=max(results$loglik)-0.5*qchisq(df=1,p=0.95)
    )
  @
  
\end{frame}

\begin{frame}[fragile,allowframebreaks]{Profile over infectious period}

  To make inferences about $\mu_{IR}$, we can again compute a profile likelihood.
  As before, we bound the region we will search:

  <<mu_IR_profile1a>>=
  read_csv("measles_params.csv") %>%
    filter(
      loglik>max(loglik)-20,
      loglik.se<2,
      abs(rho-0.6)<0.01
    ) %>%
    sapply(range) -> box
  @

  \framebreak

  <<mu_IR_profile1b>>=
  set.seed(610408798)
  profileDesign(
    mu_IR=seq(0.5,2,by=0.1),
    lower=box[1,c("Beta","eta")],
    upper=box[2,c("Beta","eta")],
    nprof=100, type="runif"
  ) %>%
    mutate(
      N=38000,
      rho=0.6
    ) -> guesses
  @
  
  \framebreak

  <<mu_IR_profile2,eval=FALSE,purl=FALSE>>=
  foreach(guess=iter(guesses,"row"), .combine=rbind) %dopar% {
    library(pomp)
    library(tidyverse)
    measSIR %>%
      mif2(params=guess, Np=2000, Nmif=100,
           partrans=parameter_trans(log="Beta",logit="eta"),
           paramnames=c("Beta","eta"), cooling.fraction.50=0.5,
           rw.sd=rw.sd(Beta=0.02,eta=ivp(0.02))
           ) %>% mif2(Nmif=100) %>%
      mif2(Nmif=100,cooling.fraction.50=0.3) %>%
      mif2(Nmif=100,cooling.fraction.50=0.1) -> mf
    replicate(10,mf %>% pfilter(Np=100000) %>% logLik()) %>%
      logmeanexp(se=TRUE) -> ll
    mf %>% coef() %>% bind_rows() %>%
      bind_cols(loglik=ll[1],loglik.se=ll[2])
  } -> results
  @
  
  <<mu_IR_profile_eval,include=FALSE>>=
  registerDoRNG(610408798)
  bake(file="mu_IR_profile1.rds",{
    <<mu_IR_profile2>>
    attr(results,"ncpu") <- getDoParWorkers()
    results
  }) %>%
    filter(is.finite(loglik)) -> results
  t_muIR <- attr(results,"system.time")
  ncpu_muIR <- attr(results,"ncpu")
  @

  <<include=FALSE,cache=FALSE>>=
  read_csv("measles_params.csv") %>%
    bind_rows(results) %>%
    filter(is.finite(loglik)) %>%
    arrange(-loglik) %>%
    write_csv("measles_params.csv")
  @

\end{frame}

\begin{frame}[fragile,allowframebreaks]{Infectious period profile}

  <<mu_IR_profile_plot>>=
  results %>%
    group_by(round(mu_IR,2)) %>%
    filter(rank(-loglik)<3) %>%
    ungroup() %>%
    ggplot(aes(x=mu_IR,y=loglik))+
    geom_point()+
    geom_hline(
      color="red",
      yintercept=max(results$loglik)-0.5*qchisq(df=1,p=0.95)
    )
  @

  \framebreak

  \begin{itemize}
  \item This suggests that $\rho=0.6$ is consistent only with smaller values of $\mu_{IR}$, and hence \emph{longer} infectious periods than are possible if the duration of shedding is actually less than one week.
  \item Thus the model is incapable of reconciling both an infectious period of less than one week and a reporting rate of 60\%.
  \item \emph{What structural changes to the model might we make to improve its ability to explain the data?}
  \end{itemize}

\end{frame}

\section{Exercises}

\begin{frame}{Basic Exercise: Fitting the SEIR model}
  Following the template above, estimate the parameters and likelihood of the SEIR model you implemented in the earlier lessons.
  Specifically:
  \begin{enumerate}[(a)]
  \item First conduct a local search and then a global search using the multi-stage, multi-start method displayed above.
  \item How does the maximized likelihood compare with what we obtained for the SIR model?
  \item How do the parameter estimates differ?
  \end{enumerate}

  You will need to tailor the intensity of your search to the computational resources at your disposal.
  In particular, choose the number of starts, number of particles employed, and the number of IF2 iterations to perform in view of the size and speed of your machine.
\end{frame}

\begin{frame}{Extra Exercise: Modify the measurement model}
  The binomial measurement model used here assumes that the reporting rate is fixed through time and that all infections are equally likely to be reported.
  Formulate an alternative measurement model and maximize the likelihood to compare it with existing results.
\end{frame}

\begin{frame}{Extra Exercise: Construct a profile likelihood}
  How strong is the evidence about the contact rate, $\beta$, given this model and data?
  Use \code{mif2} to construct a profile likelihood.
  Due to time constraints, you may be able to compute only a preliminary version.

  It is also possible to profile over the basic reproduction number, $R_0=\beta /\mu_{IR}$.
  Is this more or less well determined than $\beta$ for this model and data?
\end{frame}

\begin{frame}[allowframebreaks]{Extra Exercise: Checking the source code}

  Check the source code for the \code{measSIR} pomp object.
  Does the code implement the model described?

  \framebreak

  For various reasons, it can be surprisingly hard to make sure that the written equations and the code are perfectly matched.
  Here are some things to think about

  Papers should be written to be readable.
  Code must be written to run successfully.
  People rarely choose to clutter papers with numerical details which they hope and believe are scientifically irrelevant.
  \begin{enumerate}[(a)]
  \item What problems can arise due to the conflict between readability and reproducibility?
  \item What solutions are available?
  \end{enumerate}

  \framebreak

  Suppose that there is an error in the coding of \code{rprocess} and suppose that plug-and-play statistical methodology is used to infer parameters.
  As a conscientious researcher, you carry out a simulation study to check the soundness of your inference methodology on this model.
  To do this, you use \code{simulate} to generate realizations from the fitted model and checking that your parameter inference procedure recovers the known parameters, up to some statistical error.
  \begin{enumerate}[(a)]
  \item Will this procedure help to identify the error in \code{rprocess}?
  \item If not, how might you debug \code{rprocess}?
  \item What research practices help minimize the risk of errors in simulation code?
  \end{enumerate}
\end{frame}

\begin{frame}{Extra Exercise: Choosing the algorithmic settings for IF2}
  Have a look at \link{./if2_settings.html}{our advice on tuning IF2}.
\end{frame}

\mode<presentation>{
  \begin{frame}[allowframebreaks=0.8]{References}
    \bibliographystyle{prslb}
    \bibliography{../sbied}
  \end{frame}
}
\mode<article>{
  \bibliographystyle{prslb}
  \bibliography{../sbied}
}

\begin{frame}{License, acknowledgments, and links}

  \begin{itemize}
  \item
    This lesson is prepared for the \link{https://kingaa.github.io/sbied/}{Simulation-based Inference for Epidemiological Dynamics} module at the 2020 Summer Institute in Statistics and Modeling in Infectious Diseases, \link{https://www.biostat.washington.edu/suminst/sismid}{SISMID 2020}.

  \item
    The materials build on \link{../acknowledge.html}{previous versions of this course and related courses}.

  \item
    Licensed under the \link{http://creativecommons.org/licenses/by-nc/4.0/}{Creative Commons Attribution-NonCommercial license}.
    Please share and remix non-commercially, mentioning its origin.
    \includegraphics[height=12pt]{../graphics/cc-by-nc}

  \item
    Produced with R version \Sexpr{getRversion()} and \package{pomp} version \Sexpr{packageVersion("pomp")}.

  \end{itemize}

  \link{../index.html}{Back to course homepage}
  
  \link{https://raw.githubusercontent.com/kingaa/sbied/master/mif/mif.R}{\Rlanguage code for this lesson}

\end{frame}

\end{document}
